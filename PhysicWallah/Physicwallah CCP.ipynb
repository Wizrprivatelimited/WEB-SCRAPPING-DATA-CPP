{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4461db8",
   "metadata": {},
   "source": [
    "Course link Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53ed20b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Extracted 78 courses from Physics Wallah!\n",
      "ðŸ“‚ Saved to: C:\\Users\\taslim.siddiqui\\Downloads\\PhysicsWallah_Courses_Complete.xlsx\n",
      "\n",
      "Sample Courses:\n",
      "                     Course Name                                      Course Link\n",
      "                       ACCA Exam                         https://www.pw.live/acca\n",
      "                           AE/JE                        https://www.pw.live/ae-je\n",
      "        Agniveer Online Coaching     https://www.pw.live/defence/agniveer/batches\n",
      "Agriculture Exam Online Coaching          https://www.pw.live/agriculture/batches\n",
      "               Agriculture Exams                  https://www.pw.live/agriculture\n",
      "            BPSC Online Coaching       https://www.pw.live/state-psc/bpsc/batches\n",
      "       Bank Exam Online Coaching              https://www.pw.live/banking/batches\n",
      "                    Banking Exam                      https://www.pw.live/banking\n",
      "      Bihar Exam Online Coaching                https://www.pw.live/bihar/batches\n",
      "                         CA Exam                          https://www.pw.live/ca/\n",
      "                CA/Finance Books https://store.pw.live/ug-entrance-exams/ca-books\n",
      "            CDS Offline Coaching  https://www.pw.live/defence/cds-offline/batches\n",
      "             CDS Online Coaching    https://www.pw.live/defence/cds-afcat/batches\n",
      "                     CS Coaching              https://www.pw.live/gate/cs/batches\n",
      "                   CSIR-NET Exam               https://www.pw.live/csir-net/exams\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def extract_pw_courses(html_content, base_url=\"https://www.pw.live\"):\n",
    "    \"\"\"Extract ALL course names and links from Physics Wallah HTML\"\"\"\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    courses = []\n",
    "    \n",
    "    # Look for course links in multiple potential locations\n",
    "    # 1. Main navigation menu items\n",
    "    nav_links = soup.select('nav a[href], .flex a[href], .flex-col a[href]')\n",
    "    \n",
    "    # 2. Course category sections\n",
    "    course_sections = soup.select('a[href*=\"/batches\"], a[href*=\"/online-course\"]')\n",
    "    \n",
    "    # 3. Exam category links\n",
    "    exam_links = soup.select('a[href*=\"/iit-jee\"], a[href*=\"/neet\"], a[href*=\"/upsc\"], a[href*=\"/gate\"]')\n",
    "    \n",
    "    # 4. Footer course links\n",
    "    footer_links = soup.select('footer a[href]')\n",
    "    \n",
    "    # Combine all potential course links\n",
    "    all_links = nav_links + course_sections + exam_links + footer_links\n",
    "    \n",
    "    for link in all_links:\n",
    "        href = link.get('href', '').strip()\n",
    "        text = link.get_text(strip=True)\n",
    "        \n",
    "        # Skip if no href or text is too short\n",
    "        if not href or len(text) < 2:\n",
    "            continue\n",
    "            \n",
    "        # Skip non-course links\n",
    "        if (href.startswith(('#', 'mailto:', 'tel:')) or\n",
    "            any(x in href for x in ['/about', '/contact', '/privacy', '/terms', 'facebook', 'twitter', \n",
    "                                   'instagram', 'youtube', 'linkedin', '.jpg', '.png', '.webp'])):\n",
    "            continue\n",
    "        \n",
    "        # Make sure it's a course-related link\n",
    "        if (any(x in href for x in ['/batches', '/online-course', '/iit-jee', '/neet', '/upsc', '/gate',\n",
    "                                  '/ssc', '/banking', '/teaching', '/defence', '/ca', '/olympiad', '/mba',\n",
    "                                  '/commerce', '/cuet', '/ae-je', '/law', '/ese-gate', '/ipmat', '/ielts']) or\n",
    "            any(x in text.lower() for x in ['batch', 'course', 'program', 'coaching', 'exam', 'preparation'])):\n",
    "            \n",
    "            full_url = urljoin(base_url, href)\n",
    "            \n",
    "            courses.append({\n",
    "                \"Course Name\": re.sub(r'\\s+', ' ', text),\n",
    "                \"Course Link\": full_url\n",
    "            })\n",
    "    \n",
    "    # Remove duplicates\n",
    "    df = pd.DataFrame(courses).drop_duplicates(subset=[\"Course Link\", \"Course Name\"])\n",
    "    return df.sort_values(\"Course Name\").reset_index(drop=True)\n",
    "\n",
    "def main():\n",
    "    # Load HTML file\n",
    "    with open(r\"C:\\Users\\taslim.siddiqui\\Downloads\\Physics wallah Live Courses for JEE, NEET & Class 6,7,8,9,10,11,12 _ NCERT Solutions - Physics Wallah.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "        html = f.read()\n",
    "    \n",
    "    # Extract courses\n",
    "    df = extract_pw_courses(html)\n",
    "    \n",
    "    # Save to Excel\n",
    "    output_path = \"C:\\\\Users\\\\taslim.siddiqui\\\\Downloads\\\\PhysicsWallah_Courses_Complete.xlsx\"\n",
    "    df.to_excel(output_path, index=False)\n",
    "    \n",
    "    print(f\"âœ… Extracted {len(df)} courses from Physics Wallah!\")\n",
    "    print(f\"ðŸ“‚ Saved to: {output_path}\\n\")\n",
    "    print(\"Sample Courses:\")\n",
    "    print(df.head(15).to_string(index=False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3934c070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting scraping process for 2 links...\n",
      "ðŸŒ Accessing URL: https://www.pw.live/offline-centres/batches/vidyapeeth/kota-rj/kota-vidyapeeth-072989/neet-coaching/vidyapeeth-11th-neet--target-2026--969326\n",
      "ðŸŒ Accessing URL: https://www.pw.live/offline-centres/batches/vidyapeeth/agra-up/agra-vidyapeeth--pathshala-centre--375574/iit-jee-coaching/vidyapeeth-dropper-jee--target-2025--109274\n",
      "ðŸšª Browser closed\n",
      "\n",
      "âœ… Data saved to course_data.xlsx\n",
      "                            Course Name  \\\n",
      "0    Vidyapeeth 11th NEET (Target 2026)   \n",
      "1  Vidyapeeth DROPPER JEE (Target 2025)   \n",
      "\n",
      "                                       Learning Mode  \\\n",
      "0  Smart Interactive Classroom Configuration for ...   \n",
      "1  7. Vidyapeeth Centers Offline Counseling Services   \n",
      "\n",
      "                                            Features  \\\n",
      "0  Live session with PW Star Faculty; Get tips & ...   \n",
      "1  Live session with PW Star Faculty; Get tips & ...   \n",
      "\n",
      "                                                 URL  \n",
      "0  https://www.pw.live/offline-centres/batches/vi...  \n",
      "1  https://www.pw.live/offline-centres/batches/vi...  \n"
     ]
    }
   ],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# -------------------- DRIVER SETUP --------------------\n",
    "def get_driver():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--window-size=1280,720\")\n",
    "    options.add_argument(\"--log-level=3\")\n",
    "    driver = uc.Chrome(options=options, version_main=138)\n",
    "    return driver\n",
    "\n",
    "# -------------------- SCRAPER --------------------\n",
    "def scrape_course_data(driver, url):\n",
    "    try:\n",
    "        print(f\"ðŸŒ Accessing URL: {url}\")\n",
    "        driver.get(url)\n",
    "\n",
    "        # wait for body\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "        )\n",
    "        time.sleep(2)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # -------- Course Name --------\n",
    "        course_name = \"Course name not available\"\n",
    "        h1_tag = soup.find(\"h1\")\n",
    "        if h1_tag:\n",
    "            course_name = h1_tag.get_text(strip=True)\n",
    "\n",
    "        # -------- Learning Mode --------\n",
    "        learning_mode = \"Learning mode not available\"\n",
    "        try:\n",
    "            mode_el = driver.find_element(\n",
    "                By.XPATH,\n",
    "                \"//span[contains(text(),'Live') or contains(text(),'Online') or contains(text(),'Offline')]\"\n",
    "            )\n",
    "            learning_mode = mode_el.text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # -------- Features (like \"Live session with PW Star Faculty\") --------\n",
    "        features = []\n",
    "        try:\n",
    "            feature_tags = soup.find_all(\"div\", class_=\"Counselling_featureItem__791_G\")\n",
    "            for f in feature_tags:\n",
    "                text_span = f.find(\"span\")\n",
    "                if text_span:\n",
    "                    features.append(text_span.get_text(strip=True))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return {\n",
    "            \"Course Name\": course_name,\n",
    "            \"Learning Mode\": learning_mode,\n",
    "            \"Features\": \"; \".join(features) if features else \"Not available\",\n",
    "            \"URL\": url\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ðŸ”¥ Scraping failed for {url}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# -------------------- MAIN --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    course_urls = [\n",
    "        \"https://www.pw.live/offline-centres/batches/vidyapeeth/kota-rj/kota-vidyapeeth-072989/neet-coaching/vidyapeeth-11th-neet--target-2026--969326\",\n",
    "        \"https://www.pw.live/offline-centres/batches/vidyapeeth/agra-up/agra-vidyapeeth--pathshala-centre--375574/iit-jee-coaching/vidyapeeth-dropper-jee--target-2025--109274\"\n",
    "    ]\n",
    "\n",
    "    print(f\"ðŸš€ Starting scraping process for {len(course_urls)} links...\")\n",
    "    driver = get_driver()\n",
    "    results = []\n",
    "\n",
    "    for url in course_urls:\n",
    "        data = scrape_course_data(driver, url)\n",
    "        if data:\n",
    "            results.append(data)\n",
    "\n",
    "    driver.quit()\n",
    "    print(\"ðŸšª Browser closed\")\n",
    "\n",
    "    if results:\n",
    "        df = pd.DataFrame(results)\n",
    "        df.to_excel(r\"C:\\Users\\taslim.siddiqui\\Downloads\\course_data.xlsx\", index=False)\n",
    "        print(\"\\nâœ… Data saved to course_data.xlsx\")\n",
    "        print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd45ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f6308e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad60e3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting scraping process for 2 links...\n",
      "ðŸŒ Accessing URL: https://www.pw.live/offline-centres/batches/vidyapeeth/kota-rj/kota-vidyapeeth-072989/neet-coaching/vidyapeeth-11th-neet--target-2026--969326\n",
      "ðŸŒ Accessing URL: https://www.pw.live/offline-centres/batches/vidyapeeth/agra-up/agra-vidyapeeth--pathshala-centre--375574/iit-jee-coaching/vidyapeeth-dropper-jee--target-2025--109274\n",
      "ðŸšª Browser closed\n",
      "\n",
      "âœ… Data saved to course_data.xlsx\n",
      "                            Course Name  \\\n",
      "0             Course name not available   \n",
      "1  Vidyapeeth DROPPER JEE (Target 2025)   \n",
      "\n",
      "                                       Learning Mode  \\\n",
      "0                        Learning mode not available   \n",
      "1  7. Vidyapeeth Centers Offline Counseling Servi...   \n",
      "\n",
      "                                            Features                Price  \\\n",
      "0                                      Not available  Price not available   \n",
      "1  Live session with PW Star Faculty; Get tips & ...  Price not available   \n",
      "\n",
      "                                                 URL  \n",
      "0  https://www.pw.live/offline-centres/batches/vi...  \n",
      "1  https://www.pw.live/offline-centres/batches/vi...  \n"
     ]
    }
   ],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# -------------------- DRIVER SETUP --------------------\n",
    "def get_driver():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--window-size=1280,720\")\n",
    "    options.add_argument(\"--log-level=3\")\n",
    "    driver = uc.Chrome(options=options)  # auto detect Chrome version\n",
    "    return driver\n",
    "\n",
    "# -------------------- SCRAPER --------------------\n",
    "def scrape_course_data(driver, url):\n",
    "    try:\n",
    "        print(f\"ðŸŒ Accessing URL: {url}\")\n",
    "        driver.get(url)\n",
    "\n",
    "        # wait for body\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "        )\n",
    "        time.sleep(2)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # -------- Course Name --------\n",
    "        course_name = \"Course name not available\"\n",
    "        h1_tag = soup.find(\"h1\")\n",
    "        if h1_tag:\n",
    "            course_name = h1_tag.get_text(strip=True)\n",
    "\n",
    "        # -------- Learning Mode --------\n",
    "        learning_mode = \"Learning mode not available\"\n",
    "        try:\n",
    "            mode_els = driver.find_elements(\n",
    "                By.XPATH,\n",
    "                \"//span[contains(text(),'Live') or contains(text(),'Online') or contains(text(),'Offline')]\"\n",
    "            )\n",
    "            if mode_els:\n",
    "                learning_mode = \"; \".join([el.text.strip() for el in mode_els if el.text.strip()])\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error extracting learning mode: {e}\")\n",
    "\n",
    "        # -------- Features (like \"Live session with PW Star Faculty\") --------\n",
    "        features = []\n",
    "        try:\n",
    "            feature_tags = soup.select(\"div.Counselling_featureItem__791_G span\")\n",
    "            features = [f.get_text(strip=True) for f in feature_tags]\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error extracting features: {e}\")\n",
    "        features = \"; \".join(features) if features else \"Not available\"\n",
    "\n",
    "        # -------- Price --------\n",
    "        price = \"Price not available\"\n",
    "        try:\n",
    "            # Find any h4 that contains the rupee symbol\n",
    "            price_tag = soup.find(\"h4\", string=lambda t: t and \"â‚¹\" in t)\n",
    "            if price_tag:\n",
    "                price = price_tag.get_text(strip=True)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error extracting price: {e}\")\n",
    "\n",
    "        return {\n",
    "            \"Course Name\": course_name,\n",
    "            \"Learning Mode\": learning_mode,\n",
    "            \"Features\": features,\n",
    "            \"Price\": price,   # e.g. \"â‚¹ 1,45,000\"\n",
    "            \"URL\": url\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ðŸ”¥ Scraping failed for {url}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# -------------------- MAIN --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    course_urls = [\n",
    "        \"https://www.pw.live/offline-centres/batches/vidyapeeth/kota-rj/kota-vidyapeeth-072989/neet-coaching/vidyapeeth-11th-neet--target-2026--969326\",\n",
    "        \"https://www.pw.live/offline-centres/batches/vidyapeeth/agra-up/agra-vidyapeeth--pathshala-centre--375574/iit-jee-coaching/vidyapeeth-dropper-jee--target-2025--109274\"\n",
    "    ]\n",
    "\n",
    "    print(f\"ðŸš€ Starting scraping process for {len(course_urls)} links...\")\n",
    "    driver = get_driver()\n",
    "    results = []\n",
    "\n",
    "    for url in course_urls:\n",
    "        data = scrape_course_data(driver, url)\n",
    "        if data:\n",
    "            results.append(data)\n",
    "\n",
    "    driver.quit()\n",
    "    print(\"ðŸšª Browser closed\")\n",
    "\n",
    "    if results:\n",
    "        df = pd.DataFrame(results)\n",
    "        df.to_excel(r\"C:\\Users\\taslim.siddiqui\\Downloads\\course_data.xlsx\", index=False)\n",
    "        print(\"\\nâœ… Data saved to course_data.xlsx\")\n",
    "        print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
