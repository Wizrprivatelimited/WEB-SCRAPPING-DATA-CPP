{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b501e45",
   "metadata": {},
   "source": [
    "CERTYBOX LINK EXTRACTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313f138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Configuration\n",
    "BASE_URL = \"https://www.certybox.com\"\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "MAX_THREADS = 8\n",
    "\n",
    "# Storage\n",
    "course_data = []\n",
    "visited_urls = set()\n",
    "\n",
    "def is_course_page(url):\n",
    "    \"\"\"Strict check for course pages only (no categories)\"\"\"\n",
    "    patterns = [\n",
    "        r'^/courses/[^/]+/?$',\n",
    "        r'^/course/[^/]+/?$',\n",
    "        r'^/training/[^/]+/?$',\n",
    "        r'^/certification/[^/]+/?$',\n",
    "        r'^/program/[^/]+/?$'\n",
    "    ]\n",
    "    path = urlparse(url.lower()).path\n",
    "    return any(re.match(pattern, path) for pattern in patterns)\n",
    "\n",
    "def is_discovery_page(url):\n",
    "    \"\"\"Identify pages that may contain course links\"\"\"\n",
    "    path = urlparse(url.lower()).path\n",
    "    return not bool(re.search(r'course-category|category|topic|subject', path))\n",
    "\n",
    "def extract_course_info(url):\n",
    "    \"\"\"Extract course name from its page\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS, timeout=10)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Try multiple ways to find course name\n",
    "        name_selectors = [\n",
    "            'h1.product_title', 'h1.course-title', 'h1.entry-title',\n",
    "            'h1.title', 'h1.page-title', 'title'\n",
    "        ]\n",
    "        \n",
    "        for selector in name_selectors:\n",
    "            name = soup.select_one(selector)\n",
    "            if name:\n",
    "                course_name = re.sub(r'\\s+', ' ', name.get_text(strip=True)).strip()\n",
    "                return course_name\n",
    "        \n",
    "        return \"Unknown Course Name\"\n",
    "    except:\n",
    "        return \"Unknown Course Name\"\n",
    "\n",
    "def process_page(url):\n",
    "    \"\"\"Process a page to find courses and their names\"\"\"\n",
    "    if url in visited_urls:\n",
    "        return\n",
    "    visited_urls.add(url)\n",
    "    \n",
    "    print(f\"Processing: {url}\")\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS, timeout=10)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Method 1: Course cards\n",
    "        for card in soup.find_all(class_=re.compile(r'course|product|training|certification', re.I)):\n",
    "            link = card.find('a', href=True)\n",
    "            if link:\n",
    "                full_url = urljoin(BASE_URL, link['href'])\n",
    "                if is_course_page(full_url):\n",
    "                    name = extract_course_name_from_card(card) or extract_course_info(full_url)\n",
    "                    course_data.append({\n",
    "                        \"Course Name\": name,\n",
    "                        \"Course Link\": full_url\n",
    "                    })\n",
    "        \n",
    "        # Method 2: Direct links\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            full_url = urljoin(BASE_URL, link['href'])\n",
    "            if is_course_page(full_url):\n",
    "                name = link.get_text(strip=True)\n",
    "                if len(name.split()) > 2:  # Filter out short/non-descriptive links\n",
    "                    course_data.append({\n",
    "                        \"Course Name\": re.sub(r'\\s+', ' ', name).strip(),\n",
    "                        \"Course Link\": full_url\n",
    "                    })\n",
    "        \n",
    "        # Handle pagination\n",
    "        pagination = soup.find(class_=re.compile(r'pagination|page-numbers', re.I))\n",
    "        if pagination:\n",
    "            for page in pagination.find_all('a', href=True):\n",
    "                page_url = urljoin(BASE_URL, page['href'])\n",
    "                if is_discovery_page(page_url) and page_url not in visited_urls:\n",
    "                    process_page(page_url)\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {url}: {str(e)}\")\n",
    "\n",
    "def extract_course_name_from_card(card):\n",
    "    \"\"\"Extract name from course card element\"\"\"\n",
    "    name = card.find(class_=re.compile(r'title|name|heading', re.I)) or card.find(['h2', 'h3', 'h4'])\n",
    "    return name.get_text(strip=True) if name else None\n",
    "\n",
    "def main():\n",
    "    print(\"üöÄ Starting CertyBox course extraction...\")\n",
    "    \n",
    "    # Entry points that contain course listings\n",
    "    entry_points = [\n",
    "        BASE_URL + \"/courses/\",\n",
    "    ]\n",
    "    \n",
    "    # Multi-threaded processing\n",
    "    with ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n",
    "        executor.map(process_page, entry_points)\n",
    "    \n",
    "    # Process results\n",
    "    if course_data:\n",
    "        df = pd.DataFrame(course_data)\n",
    "        df = df.drop_duplicates(subset=[\"Course Link\"]).sort_values(by=\"Course Name\")\n",
    "        \n",
    "        output_file = \"C:\\\\Users\\\\taslim.siddiqui\\\\Downloads\\\\CertyBox_Courses_With_Links.xlsx\"\n",
    "        df.to_excel(output_file, index=False)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Success! Extracted {len(df)} courses\")\n",
    "        print(f\"üìÅ Saved to: {output_file}\")\n",
    "        \n",
    "        print(\"\\n=== Sample Courses ===\")\n",
    "        print(df.head(10).to_string(index=False))\n",
    "    else:\n",
    "        print(\"‚ùå No courses found\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
