{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c0bf8e5",
   "metadata": {},
   "source": [
    "Eduonix CPP link extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad96fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import deque\n",
    "\n",
    "base_url = \"https://www.eduonix.com\"\n",
    "visited = set()\n",
    "queue = deque([base_url])\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "courses = []\n",
    "\n",
    "# Regex for course-like page ending\n",
    "course_url_regex = re.compile(r\"https://www\\.eduonix\\.com/[a-z0-9\\-]+$\", re.I)\n",
    "\n",
    "# Exclusion list for non-course pages\n",
    "excluded = [\n",
    "    \"/login\", \"/signup\", \"/cart\", \"/checkout\", \"/dashboard\", \"/profile\",\n",
    "    \"/terms\", \"/privacy\", \"/contact\", \"/about\", \"/faq\", \"/category\",\n",
    "    \".jpg\", \".png\", \".svg\", \".pdf\", \"tel:\", \"mailto:\", \"javascript:\", \"#\",\n",
    "    \"lifetime\", \"edegree\", \"infiniti\", \"deals\", \"freebies\", \"upcoming\"\n",
    "]\n",
    "\n",
    "def is_course_page(url, text):\n",
    "    return (\n",
    "        text and len(text.strip()) > 5\n",
    "        and url.startswith(base_url)\n",
    "        and not any(x in url.lower() for x in excluded)\n",
    "        and re.match(course_url_regex, url)\n",
    "        and not url.endswith(('courses', 'course'))\n",
    "    )\n",
    "\n",
    "def should_crawl(url):\n",
    "    return (\n",
    "        url.startswith(base_url)\n",
    "        and not any(x in url.lower() for x in excluded)\n",
    "        and url not in visited\n",
    "        and not url.endswith(('courses', 'course'))\n",
    "    )\n",
    "\n",
    "while queue and len(visited) < 100:  # Limit to 100 pages to prevent excessive crawling\n",
    "    current_url = queue.popleft()\n",
    "    visited.add(current_url)\n",
    "\n",
    "    try:\n",
    "        print(f\"üîç Scanning: {current_url}\")\n",
    "        r = requests.get(current_url, headers=headers, timeout=10)\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "        # Find all course links - looking for <a> tags with href and text\n",
    "        for a in soup.find_all(\"a\", href=True):\n",
    "            href = urljoin(base_url, a[\"href\"].strip())\n",
    "            text = a.get_text(strip=True)\n",
    "            \n",
    "            if should_crawl(href):\n",
    "                queue.append(href)\n",
    "                \n",
    "            if is_course_page(href, text):\n",
    "                courses.append({\n",
    "                    \"Course Name\": text,\n",
    "                    \"Course Link\": href\n",
    "                })\n",
    "                \n",
    "        # Special handling for course listing pages\n",
    "        if \"courses\" in current_url:\n",
    "            for course_card in soup.select('a[href*=\"/courses/\"]'):\n",
    "                href = urljoin(base_url, course_card[\"href\"].strip())\n",
    "                text = course_card.get_text(strip=True)\n",
    "                \n",
    "                if is_course_page(href, text):\n",
    "                    courses.append({\n",
    "                        \"Course Name\": text,\n",
    "                        \"Course Link\": href\n",
    "                    })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Skipping {current_url}: {e}\")\n",
    "\n",
    "# Deduplicate\n",
    "df = pd.DataFrame(courses).drop_duplicates(subset=\"Course Link\").reset_index(drop=True)\n",
    "\n",
    "# Save to Excel\n",
    "output_path = \"C:\\\\Users\\\\taslim.siddiqui\\\\Downloads\\\\Eduonix_Course_Links.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Extracted {len(df)} real course links.\")\n",
    "print(f\"üìÅ Saved to: {output_path}\")\n",
    "print(\"\\nSample of extracted courses:\")\n",
    "print(df.head(10).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
