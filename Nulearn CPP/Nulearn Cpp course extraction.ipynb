{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7de30f3",
   "metadata": {},
   "source": [
    "NULEARN CCDC course EXtraction test for one course "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "946981f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting scraping process...\n",
      "\n",
      "üîç Processing: https://www.nulearn.in/courses/executive-development-program-in-strategic-hr-analytics\n",
      "üåê Accessing URL: https://www.nulearn.in/courses/executive-development-program-in-strategic-hr-analytics\n",
      "üìõ Course Name: Executive Development Program in Strategic HR Analytics\n",
      "üìù About Course: The Strategic HR Analytics Course by IIM Kashipur will specifically focus on app...\n",
      "‚è≥ Duration: 6 Months\n",
      "üéì Learning Mode: Blended Learning\n",
      "üìö Syllabus extracted (68 lines)\n",
      "üí∞ Price: 1,00,000 Rs. 80,000 + GST* (Limited Time Offer)\n",
      "üìú Certificate: https://www.nulearn.in/uploads/images/SHRA-CERTIFICATE.jpg\n",
      "üôã Who Should Take It: This program will be useful for managers in multinationals, Indian business firm...\n",
      "üö™ Browser closed\n",
      "üíæ Saved data for: Executive Development Program in Strategic HR Analytics\n",
      "\n",
      "‚úÖ Process completed\n"
     ]
    }
   ],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "# -------------------- DRIVER SETUP --------------------\n",
    "def get_driver():\n",
    "    options = uc.ChromeOptions()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--window-size=1280,720\")\n",
    "    options.add_argument(\"--log-level=3\")\n",
    "    # options.add_argument(\"--headless\")  # Uncomment for headless mode\n",
    "    driver = uc.Chrome(options=options, version_main=138)\n",
    "    return driver\n",
    "\n",
    "# -------------------- SYLLABUS EXTRACTION --------------------\n",
    "def extract_syllabus(soup):\n",
    "    try:\n",
    "        syllabus_text = \"\"\n",
    "        modules = soup.find_all(\"h4\", class_=\"que\")\n",
    "        for module in modules:\n",
    "            module_title = module.get_text(strip=True)\n",
    "            syllabus_text += f\"\\nüìò {module_title}\\n\"\n",
    "\n",
    "            ul = module.find_next(\"ul\", class_=\"syllabus-list\")\n",
    "            if ul:\n",
    "                for li in ul.find_all(\"li\", class_=\"syllabus-list-iitem\"):\n",
    "                    lesson = li.get_text(strip=True)\n",
    "                    syllabus_text += f\"   - {lesson}\\n\"\n",
    "\n",
    "        return syllabus_text.strip() if syllabus_text else \"Syllabus not available\"\n",
    "    except Exception as e:\n",
    "        return f\"Syllabus extraction failed: {str(e)}\"\n",
    "\n",
    "# -------------------- HELPERS --------------------\n",
    "def extract_who_should_take_it(soup):\n",
    "    \"\"\"Find the 'Who should take it' list robustly.\"\"\"\n",
    "    heading = soup.find(\n",
    "        lambda tag: tag.name in [\"h2\", \"h3\", \"h4\"]\n",
    "        and re.search(r\"(who\\s+should\\s+(take|attend)|who\\s+is\\s+this|who\\s+can\\s+apply)\", tag.get_text(strip=True), re.I)\n",
    "    )\n",
    "    if heading:\n",
    "        ul = heading.find_next(\"ul\")\n",
    "        if ul:\n",
    "            items = [li.get_text(strip=True) for li in ul.find_all(\"li\")]\n",
    "            if items:\n",
    "                return \"; \".join(items)\n",
    "\n",
    "    ul = soup.find(\"ul\", class_=lambda c: c != \"course-elig-list\", attrs={\"style\": lambda v: v and \"Poppins\" in v})\n",
    "    if ul:\n",
    "        items = [li.get_text(strip=True) for li in ul.find_all(\"li\")]\n",
    "        if items:\n",
    "            return \"; \".join(items)\n",
    "\n",
    "    candidate = None\n",
    "    for possible in soup.find_all(\"ul\"):\n",
    "        if \"course-elig-list\" in (possible.get(\"class\") or []):\n",
    "            continue\n",
    "        lis = possible.find_all(\"li\")\n",
    "        if len(lis) >= 3:\n",
    "            candidate = possible\n",
    "            break\n",
    "    if candidate:\n",
    "        items = [li.get_text(strip=True) for li in candidate.find_all(\"li\")]\n",
    "        if items:\n",
    "            return \"; \".join(items)\n",
    "\n",
    "    return \"Not available\"\n",
    "\n",
    "# -------------------- SCRAPER --------------------\n",
    "def scrape_course_data(url):\n",
    "    driver = get_driver()\n",
    "    try:\n",
    "        print(f\"üåê Accessing URL: {url}\")\n",
    "        driver.get(url)\n",
    "\n",
    "        WebDriverWait(driver, 15).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"h1.course-page-name\"))\n",
    "        )\n",
    "\n",
    "        # scroll to load content\n",
    "        for _ in range(3):\n",
    "            driver.execute_script(\"window.scrollBy(0, window.innerHeight)\")\n",
    "            time.sleep(1)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # 1. Course Name\n",
    "        course_name_tag = soup.find(\"h1\", class_=\"course-page-name\")\n",
    "        course_name = course_name_tag.get_text(strip=True) if course_name_tag else \"Course name not found\"\n",
    "        print(f\"üìõ Course Name: {course_name}\")\n",
    "\n",
    "        # 2. About Course\n",
    "        about_section = soup.find(\"p\")\n",
    "        about_course = about_section.get_text(strip=True) if about_section else \"About course not found\"\n",
    "        print(f\"üìù About Course: {about_course[:80]}...\")\n",
    "\n",
    "        # 3. Duration & Learning Mode\n",
    "        duration = \"Duration not available\"\n",
    "        learning_mode = \"Learning mode not available\"\n",
    "\n",
    "        icon_blocks = soup.find_all(\"div\", class_=\"course-icon-block\")\n",
    "        for block in icon_blocks:\n",
    "            title_tag = block.find(\"h4\", class_=\"course-banner-sub-lael\")\n",
    "            value = title_tag.get_text(strip=True) if title_tag else \"\"\n",
    "\n",
    "            label_tag = block.find(\"div\")\n",
    "            label = label_tag.get_text(strip=True).upper() if label_tag else \"\"\n",
    "\n",
    "            if \"DURATION\" in label:\n",
    "                duration = value\n",
    "            elif \"SESSION\" in label or \"CAMPUS\" in label or \"LEARNING\" in value.upper():\n",
    "                learning_mode = value\n",
    "\n",
    "        print(f\"‚è≥ Duration: {duration}\")\n",
    "        print(f\"üéì Learning Mode: {learning_mode}\")\n",
    "\n",
    "        # 4. Syllabus\n",
    "        syllabus = extract_syllabus(soup)\n",
    "        print(f\"üìö Syllabus extracted ({len(syllabus.splitlines())} lines)\")\n",
    "\n",
    "        # 5. Price\n",
    "        price_tag = soup.find(\"h2\", class_=\"program-fee-amount\")\n",
    "        price = price_tag.get_text(\" \", strip=True) if price_tag else \"Price not available\"\n",
    "        print(f\"üí∞ Price: {price}\")\n",
    "\n",
    "        # 6. Certificate image\n",
    "        cert_tag = soup.find(\"a\", class_=\"certificate-image\")\n",
    "        cert_img = cert_tag.find(\"img\")[\"src\"] if cert_tag and cert_tag.find(\"img\") else \"Certificate not available\"\n",
    "        print(f\"üìú Certificate: {cert_img}\")\n",
    "\n",
    "        # 7. Who Should Take It\n",
    "        who_should_take_it = extract_who_should_take_it(soup)\n",
    "        print(f\"üôã Who Should Take It: {who_should_take_it[:80]}...\")\n",
    "\n",
    "        # 8. Eligibility (fixed & robust)\n",
    "        eligibility_content = []\n",
    "\n",
    "        # First eligibility block\n",
    "        elig_list = soup.find(\"ul\", class_=\"course-elig-list\")\n",
    "        if elig_list:\n",
    "            eligibility_content.append(elig_list.get_text(\" \", strip=True))\n",
    "\n",
    "        # Second eligibility block\n",
    "        elig_block = soup.find(\"div\", class_=\"eilg-block-container\")\n",
    "        if elig_block:\n",
    "            lis = elig_block.find_all(\"li\")\n",
    "            eligibility_content.extend([li.get_text(strip=True) for li in lis])\n",
    "\n",
    "        eligibility = \" \\n \".join(eligibility_content) if eligibility_content else \"Not available\"\n",
    "\n",
    "        return (\n",
    "            course_name,\n",
    "            about_course,\n",
    "            syllabus,\n",
    "            price,\n",
    "            duration,\n",
    "            learning_mode,\n",
    "            cert_img,\n",
    "            who_should_take_it,\n",
    "            eligibility\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"üî• Scraping failed for {url}: {str(e)}\")\n",
    "        return [\"Error\"] * 9\n",
    "    finally:\n",
    "        driver.quit()\n",
    "        print(\"üö™ Browser closed\")\n",
    "\n",
    "# -------------------- SAVE TO EXCEL --------------------\n",
    "def save_to_excel(data, file_path, url):\n",
    "    columns = [\n",
    "        \"Course Name\",\n",
    "        \"About Course\",\n",
    "        \"Syllabus\",\n",
    "        \"Price\",\n",
    "        \"Duration\",\n",
    "        \"Learning Mode\",\n",
    "        \"Certificate\",\n",
    "        \"Who Should Take It\",\n",
    "        \"Eligibility\",\n",
    "        \"Course URL\"\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_excel(file_path)\n",
    "            for col in columns:\n",
    "                if col not in df.columns:\n",
    "                    df[col] = None\n",
    "        else:\n",
    "            df = pd.DataFrame(columns=columns)\n",
    "\n",
    "        existing_urls = df[\"Course URL\"].tolist() if \"Course URL\" in df.columns else []\n",
    "        if url in existing_urls:\n",
    "            print(f\"üîÑ Course already exists: {data[0]}\")\n",
    "            return\n",
    "\n",
    "        new_row = pd.DataFrame([dict(zip(columns, [*data, url]))])\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "        df.to_excel(file_path, index=False)\n",
    "        print(f\"üíæ Saved data for: {data[0]}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Excel save error: {e}\")\n",
    "\n",
    "# -------------------- MAIN --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    course_urls = [\n",
    "        \"https://www.nulearn.in/courses/executive-development-program-in-strategic-hr-analytics\"\n",
    "    ]\n",
    "\n",
    "    print(\"üöÄ Starting scraping process...\")\n",
    "    file_path = r\"C:\\Users\\taslim.siddiqui\\Downloads\\course00.xlsx\"\n",
    "\n",
    "    for course_url in course_urls:\n",
    "        print(f\"\\nüîç Processing: {course_url}\")\n",
    "        course_data = scrape_course_data(course_url)\n",
    "        if all(item != \"Error\" for item in course_data):\n",
    "            save_to_excel(course_data, file_path, course_url)\n",
    "        else:\n",
    "            print(f\"‚ùå Failed to scrape complete data for {course_url}\")\n",
    "\n",
    "    print(\"\\n‚úÖ Process completed\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
